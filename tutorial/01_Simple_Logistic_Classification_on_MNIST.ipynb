{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Tutorial 1: Simple Logistic Classification on MNIST\n",
    "\n",
    "初次學習Tensorflow最困難的地方莫過於不知道從何下手，已經學會很多的Deep Learning理論，但是要自己使用Tensorflow將Network建起來卻是非常困難的，這篇文章我試著去建立一個最簡單的分類模型，從模型的建立過程一邊學習Tensorflow如何運作。\n",
    "\n",
    "## MNIST Dataset\n",
    "\n",
    "首先，先`import`一些會用到的function，並且定義`summary` function以便於觀察ndarray。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline\n",
    "\n",
    "def summary(ndarr):\n",
    "    print(ndarr)\n",
    "    print(\"* shape: {}\".format(ndarr.shape))\n",
    "    print(\"* min: {}\".format(np.min(ndarr)))\n",
    "    print(\"* max: {}\".format(np.max(ndarr)))\n",
    "    print(\"* avg: {}\".format(np.mean(ndarr)))\n",
    "    print(\"* std: {}\".format(np.std(ndarr)))\n",
    "    print(\"* unique: {}\".format(np.unique(ndarr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ndarray是numpy的基本元素，它非常便於我們做矩陣的運算。\n",
    "\n",
    "接下來下載MNIST Dataset當作我們練習的標的，在Tensorflow你可以很簡單的得到「處理過後的」MNIST，MNIST包含一堆手寫數字的圖片，每張圖片大小為28x28，每一張圖片都是一個手寫的阿拉伯數字包含0到9，並且標上它所對應的數字。我們的目標就是要利用MNIST做到手寫數字辨識，給出它相應的數字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "train_data = mnist.train\n",
    "valid_data = mnist.validation\n",
    "test_data = mnist.test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每個`train_data`、`valid_data`、`test_data`都包含兩部分：圖片和標籤。\n",
    "\n",
    "我們來看一下圖片的部分，`train_data`一共有55000張圖，每一張圖原本大小是28x28，不過特別注意這裡的Data已經先做過預先處理了，因此圖片已經被打平成28x28=784的一維矩陣了，另外每個Pixel的值也先做過「Normalization」了，通常會這樣處理，減去128再除以128，所以你可以從`summary`中看到它的最大最小值落在0到1之間，另外這個Dataset也已經做過亂數重排了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]]\n",
      "* shape: (55000, 784)\n",
      "* min: 0.0\n",
      "* max: 1.0\n",
      "* avg: 0.13070042431354523\n",
      "* std: 0.30815958976745605\n",
      "* unique: [ 0.          0.00392157  0.00784314  0.01176471  0.01568628  0.01960784\n",
      "  0.02352941  0.02745098  0.03137255  0.03529412  0.03921569  0.04313726\n",
      "  0.04705883  0.0509804   0.05490196  0.05882353  0.0627451   0.06666667\n",
      "  0.07058824  0.07450981  0.07843138  0.08235294  0.08627451  0.09019608\n",
      "  0.09411766  0.09803922  0.10196079  0.10588236  0.10980393  0.1137255\n",
      "  0.11764707  0.12156864  0.1254902   0.12941177  0.13333334  0.13725491\n",
      "  0.14117648  0.14509805  0.14901961  0.15294118  0.15686275  0.16078432\n",
      "  0.16470589  0.16862746  0.17254902  0.17647059  0.18039216  0.18431373\n",
      "  0.18823531  0.19215688  0.19607845  0.20000002  0.20392159  0.20784315\n",
      "  0.21176472  0.21568629  0.21960786  0.22352943  0.227451    0.23137257\n",
      "  0.23529413  0.2392157   0.24313727  0.24705884  0.25098041  0.25490198\n",
      "  0.25882354  0.26274511  0.26666668  0.27058825  0.27450982  0.27843139\n",
      "  0.28235295  0.28627452  0.29019609  0.29411766  0.29803923  0.3019608\n",
      "  0.30588236  0.30980393  0.3137255   0.31764707  0.32156864  0.32549021\n",
      "  0.32941177  0.33333334  0.33725491  0.34117648  0.34509805  0.34901962\n",
      "  0.35294119  0.35686275  0.36078432  0.36470589  0.36862746  0.37254903\n",
      "  0.37647063  0.38039219  0.38431376  0.38823533  0.3921569   0.39607847\n",
      "  0.40000004  0.4039216   0.40784317  0.41176474  0.41568631  0.41960788\n",
      "  0.42352945  0.42745101  0.43137258  0.43529415  0.43921572  0.44313729\n",
      "  0.44705886  0.45098042  0.45490199  0.45882356  0.46274513  0.4666667\n",
      "  0.47058827  0.47450984  0.4784314   0.48235297  0.48627454  0.49019611\n",
      "  0.49411768  0.49803925  0.50196081  0.50588238  0.50980395  0.51372552\n",
      "  0.51764709  0.52156866  0.52549022  0.52941179  0.53333336  0.53725493\n",
      "  0.5411765   0.54509807  0.54901963  0.5529412   0.55686277  0.56078434\n",
      "  0.56470591  0.56862748  0.57254905  0.57647061  0.58039218  0.58431375\n",
      "  0.58823532  0.59215689  0.59607846  0.60000002  0.60392159  0.60784316\n",
      "  0.61176473  0.6156863   0.61960787  0.62352943  0.627451    0.63137257\n",
      "  0.63529414  0.63921571  0.64313728  0.64705884  0.65098041  0.65490198\n",
      "  0.65882355  0.66274512  0.66666669  0.67058825  0.67450982  0.67843139\n",
      "  0.68235296  0.68627453  0.6901961   0.69411767  0.69803923  0.7019608\n",
      "  0.70588237  0.70980394  0.71372551  0.71764708  0.72156864  0.72549021\n",
      "  0.72941178  0.73333335  0.73725492  0.74117649  0.74509805  0.74901962\n",
      "  0.75294125  0.75686282  0.76078439  0.76470596  0.76862752  0.77254909\n",
      "  0.77647066  0.78039223  0.7843138   0.78823537  0.79215693  0.7960785\n",
      "  0.80000007  0.80392164  0.80784321  0.81176478  0.81568635  0.81960791\n",
      "  0.82352948  0.82745105  0.83137262  0.83529419  0.83921576  0.84313732\n",
      "  0.84705889  0.85098046  0.85490203  0.8588236   0.86274517  0.86666673\n",
      "  0.8705883   0.87450987  0.87843144  0.88235301  0.88627458  0.89019614\n",
      "  0.89411771  0.89803928  0.90196085  0.90588242  0.90980399  0.91372555\n",
      "  0.91764712  0.92156869  0.92549026  0.92941183  0.9333334   0.93725497\n",
      "  0.94117653  0.9450981   0.94901967  0.95294124  0.95686281  0.96078438\n",
      "  0.96470594  0.96862751  0.97254908  0.97647065  0.98039222  0.98431379\n",
      "  0.98823535  0.99215692  0.99607849  1.        ]\n"
     ]
    }
   ],
   "source": [
    "summary(train_data.images)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "來試著畫圖來看看，我們使用ndarray的index功能來選出第10張，`train_data.images[10,:]`表示的是選第一軸的第10個和第二軸的全部。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_fatten_img(ndarr):\n",
    "    img = ndarr.copy()\n",
    "    img.shape = (28,28)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nB4Ii/EBQhB8I6v8A+Md7QMI5IyUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ef2ada0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_fatten_img(train_data.images[10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很顯而易見的，這是一個0。\n",
    "\n",
    "接下來來看標籤的部分，`train_data.labels`一樣的也是有55000筆資料，所對應的就是前面的每一張圖片，總共有10種類型:0到9，所以大小為(55000, 10)。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0. ...,  1.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  1.  0.]]\n",
      "* shape: (55000, 10)\n",
      "* min: 0.0\n",
      "* max: 1.0\n",
      "* avg: 0.1\n",
      "* std: 0.30000000000000004\n",
      "* unique: [ 0.  1.]\n"
     ]
    }
   ],
   "source": [
    "summary(train_data.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以我們來看看剛剛那張圖片的標籤，"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print(train_data.labels[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看起來的確沒錯，在0的位置標示1.，而其他地方標示為0.，所以這是一個標示為0的label，這種表示方法稱為One-Hot Encoding，它有機率的涵義，因為我已經知道這個圖片是0，所以沒有疑慮100%的機會落在0的類別上。\n",
    "\n",
    "\n",
    "\n",
    "## 分離數據的重要性\n",
    "\n",
    "在MNIST Dataset中，你會發現分為Training Dataset、Validation Dataset和Testing Dataset，這樣的作法在Machine Learning中是常見且必要的。\n",
    "\n",
    "流程是這樣的，我們會先使用Training Dataset來訓練Model，並且使用Validation Dataset來檢驗Model的好壞，也是調整Model上參數的依據，試著盡可能的壓低Validation Dataset的Error，記住！在過程中所產生的所有Models都要保留下來，以最後的Testing Dataset來做最後的挑選，挑選出能使Testing Dataset的Error最小的Model。\n",
    "\n",
    "這樣的作法就是要避免Overfitting的情況發生，也就是機器可能因為看過一筆Data，結果就把這筆Data給完整記了起來，而Data本身含有雜訊，結果就因為這樣，雜訊滲透到我們的Model裡，所以我們要確實做到分離，讓Model在測試階段時可以使用沒有看過的Data。\n",
    "\n",
    "因此，Validation Dataset的分離就是避免讓Model在Training階段看到要驗證的資料，所以更能正確的評估Model的好壞。但不幸的是，在人為調整Model的過程當中，我們會去調整參數讓Validation Dataset的Error可以降低，這樣的作法無形之中已經將Validation Dataset的資訊間接的經由人傳給了Model，所以為了避免這樣的情形，因此在最後挑選Models時，我們使用另外一筆從沒看過的資料Testing Dataset來做挑選。\n",
    "\n",
    "## 第一個Tensorflow Model\n",
    "\n",
    "以下我把這個Model寫成一個`class`，先瞄一眼我後續再慢慢的解釋。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleLogisticClassification(object):\n",
    "    def __init__(self,n_features,n_labels,learning_rate=0.5):\n",
    "        self.n_features = n_features\n",
    "        self.n_labels = n_labels\n",
    "        self.graph = tf.Graph()\n",
    "        self.build(learning_rate)\n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "        \n",
    "    def build(self,learning_rate):\n",
    "        with self.graph.as_default():\n",
    "            ### Input\n",
    "            self.features = tf.placeholder(tf.float32, shape=(None,self.n_features))\n",
    "            self.labels   = tf.placeholder(tf.int32  , shape=(None,self.n_labels))\n",
    "            \n",
    "            ### Computation\n",
    "            self.Weights = {}\n",
    "            self.Biases  = {} \n",
    "            self.Scores  = {}\n",
    "            self.Xs      = {}\n",
    "            \n",
    "            self.Weights['fc1'], self.Biases['fc1'], self.Scores['fc1'], self.Xs['fc1'] \\\n",
    "                      = self.getDenseLayer(self.features, self.n_labels, activation=tf.nn.softmax)\n",
    "            self.logits = self.Scores['fc1']\n",
    "            self.y_ = self.Xs['fc1'] \n",
    "            \n",
    "            ### Optimalization\n",
    "            self.loss = tf.reduce_mean(\n",
    "                            tf.nn.softmax_cross_entropy_with_logits(labels=self.labels,logits=self.logits))\n",
    "            \n",
    "            self.train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(self.loss)\n",
    "            \n",
    "            ### Initialization\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "            \n",
    "    def getDenseLayer(self,input_layer,n_output,activation=None):\n",
    "        n_input = int(input_layer.shape[1])\n",
    "        W = tf.Variable(\n",
    "                    tf.truncated_normal( shape=(n_input,n_output) ))\n",
    "        b = tf.Variable(tf.zeros( shape=(n_output) ))\n",
    "        s = tf.add(tf.matmul(input_layer,W),b)\n",
    "        if activation:\n",
    "            x_new = activation(s)\n",
    "        else:\n",
    "            x_new = None\n",
    "        return (W,b,s,x_new)\n",
    "    \n",
    "    def fit(self,X,y,epochs=10,validation_data=None,test_data=None):\n",
    "        self.sess.run(self.init_op)\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch %2d/%2d: \"%(epoch+1,epochs))\n",
    "            feed_dict = {self.features: X, self.labels: y}\n",
    "            _ = self.sess.run(self.train_op, feed_dict=feed_dict)\n",
    "            \n",
    "            y_ = self.predict(X)\n",
    "            train_loss = self.evaluate(X,y)\n",
    "            train_acc = self.accuracy(y_,y)\n",
    "            msg = \" loss = %8.4f, acc = %3.2f%%\" % ( train_loss, train_acc*100 )\n",
    "            \n",
    "            if validation_data:\n",
    "                val_loss = self.evaluate(validation_data[0],validation_data[1])\n",
    "                val_acc = self.accuracy(self.predict(validation_data[0]),validation_data[1])\n",
    "                msg += \", val_loss = %8.4f, val_acc = %3.2f%%\" % ( val_loss, val_acc*100 )\n",
    "            \n",
    "            print(msg)\n",
    "            \n",
    "        if test_data:\n",
    "            test_acc = self.accuracy(self.predict(test_data[0]),test_data[1])\n",
    "            print(\"test_acc = %3.2f%%\" % (test_acc*100))\n",
    "            \n",
    "    def accuracy(self, predictions, labels):\n",
    "        return (np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))/predictions.shape[0])\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return self.sess.run(self.y_, feed_dict={self.features: X})\n",
    "    \n",
    "    def evaluate(self,X,y):\n",
    "        return self.sess.run(self.loss, feed_dict={self.features: X, self.labels: y})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用物件導向的寫法，可以讓程式看起來更有條理，在這裡我就把我要訓練的Model物件化。\n",
    "\n",
    "`SimpleLogisticClassification`包含6個部分，一開始在`def __init__(...)`中先初始化這個Model，接下來在`def __structure(...)`裡頭定義Model的結構，然後使用`def fit(...)`來做Training，而`def accuracy(...)`用來計算正確率，最後兩個函數`def predict(...)`和`def evaluate(...)`則是用來推演用的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/10: \n",
      " loss =   9.5909, acc = 12.50%, val_loss =   9.5429, val_acc = 12.58%\n",
      "Epoch  2/10: \n",
      " loss =   8.4425, acc = 14.65%, val_loss =   8.4002, val_acc = 14.82%\n",
      "Epoch  3/10: \n",
      " loss =   7.5826, acc = 16.89%, val_loss =   7.5453, val_acc = 17.00%\n",
      "Epoch  4/10: \n",
      " loss =   6.9411, acc = 19.07%, val_loss =   6.9095, val_acc = 19.08%\n",
      "Epoch  5/10: \n",
      " loss =   6.4326, acc = 21.19%, val_loss =   6.4074, val_acc = 21.74%\n",
      "Epoch  6/10: \n",
      " loss =   6.0045, acc = 23.23%, val_loss =   5.9850, val_acc = 23.56%\n",
      "Epoch  7/10: \n",
      " loss =   5.6323, acc = 25.33%, val_loss =   5.6169, val_acc = 25.66%\n",
      "Epoch  8/10: \n",
      " loss =   5.3036, acc = 27.45%, val_loss =   5.2912, val_acc = 27.86%\n",
      "Epoch  9/10: \n",
      " loss =   5.0113, acc = 29.61%, val_loss =   5.0009, val_acc = 30.26%\n",
      "Epoch 10/10: \n",
      " loss =   4.7504, acc = 31.67%, val_loss =   4.7411, val_acc = 32.44%\n",
      "test_acc = 32.00%\n"
     ]
    }
   ],
   "source": [
    "model = SimpleLogisticClassification(n_features=28*28,\n",
    "                                     n_labels=10,\n",
    "                                     learning_rate= 0.5,)\n",
    "model.fit(X=train_data.images,\n",
    "          y=train_data.labels,\n",
    "          epochs=10,\n",
    "          validation_data=(valid_data.images,valid_data.labels),\n",
    "          test_data=(test_data.images,test_data.labels), )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
