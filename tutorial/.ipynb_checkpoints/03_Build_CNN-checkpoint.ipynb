{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tensorflow Tutorial 3: Build First Convolutional Neurel Network (CNN)\n",
    "\n",
    "這一章我們終於要討論到影像辨識的重頭戲啦！通常，處理影像類別我們會用Convolutional Neurel Network，聽起來很玄，不過只要了解概念你就知道為什麼要這麼做了，讓我們看下去。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 影像有什麼特性\n",
    "\n",
    "來想一下，影像具備了什麼特性？\n",
    "\n",
    "(1) 局域性：通常物件只在一個局域的範圍裡有效，而與太遠的距離無關，譬如我要找一張圖的鳥嘴，鳥嘴的呈現在一張圖當中只會出現在一個小範圍內，所以其實只需要評估這小範圍就可以判斷這是不是鳥嘴了。\n",
    "\n",
    "(2) 平移性：通常一張圖任意平移並不影響它的意義，一隻鳥不管是放在圖片的左上角還是右下角，牠都是一隻鳥。\n",
    "\n",
    "(3) 縮放性：通常一張圖我把它等比例的放大縮小是不影響它的意義的。\n",
    "\n",
    "![影像特性](https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.004.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DNN用在影像上的侷限\n",
    "\n",
    "我們剛剛看過了影像具有的三種特性：「局域性」、「平移性」和「縮放性」，那我們就拿這三種特性來檢驗上一回的DNN Classification。\n",
    "\n",
    "DNN有「局域性」嗎？沒有，因為我們把圖片攤平處理，原本應該是相鄰的關係就被打壞了，事實上DNN的結構會造成每個Input都會同時影響下一層的「每個」神經元，所以相不相鄰根本沒關係，因為每個Pixels的影響是全域的。\n",
    "\n",
    "DNN有「平移性」嗎？沒有，沒有局域性就沒有平移性。\n",
    "\n",
    "DNN有「縮放性」嗎？我們沒有一層試著去縮放，而且圖片已經被攤平了，難以做到縮放的效果。\n",
    "\n",
    "所以其實使用DNN並不能好好的詮釋影像。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolutional Neurel Network (CNN)\n",
    "\n",
    "我們需要引入新的架構來處理影像，讓它可以擁有以上三種特性，Convolutional Neurel Network (CNN)此時就登場了，CNN有兩大新要素：Convolution Layer和Pooling Layer，Convolution Layer為我們的Model添加了局域性和平移性，而Pooling Layer則讓Model擁有縮放的特性。\n",
    "\n",
    "![Convolution Layer和Pooling Layer](https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.005.jpeg)\n",
    "\n",
    "Convolution Layer是由Filters所構成的，Filters可以想像是一張小圖，以上面的例子，Filter是一個鳥嘴的小圖，這張小圖要怎麼去過濾原圖呢？答案是使用Convolution(卷積)，把小圖疊到大圖的任意位置，接下來將大圖小圖對到的相應元素相乘起來再加總一起，然後在另外一張表格中填入這個加總值，接下來移動Filter，重複的動作再做一次，如此循環並將值陸續填入表格中，這表格最後就會像是另外一張圖一樣，而這張圖可以繼續串另外的Neurel Network，這就是Convolution Layer的計算方法。\n",
    "\n",
    "舉個例子，假設我今天有矩陣A：\n",
    "\n",
    "[[1, 2, 3, 4],<br/>\n",
    " [4, 5, 6, 7],<br/>\n",
    " [7, 8, 9,10],<br/>\n",
    " [1, 3, 5, 7]]\n",
    "\n",
    "然後再有一個Filter：\n",
    "\n",
    "[[1, 0, 0],<br/>\n",
    " [0, 1, 0],<br/>\n",
    " [0, 0, 0]]\n",
    "\n",
    "使用Filter對A做Convolution得到B為：\n",
    "\n",
    "[[6, 8 ],<br/>\n",
    " [12,14]]\n",
    " \n",
    "原本3x3的矩陣做了Convolution後變成了2x2的矩陣，原因在於邊界限制了Filter的移動，那如果我想要讓Convolution玩的矩陣維持在3x3，怎麼做？我們可以在邊緣的地方鋪上0就可以達到這樣的效果，來試試看，先將矩陣A擴張成矩陣C：\n",
    "\n",
    "[[0, 0, 0, 0, 0, 0],<br/>\n",
    " [0, 1, 2, 3, 4, 0],<br/>\n",
    " [0, 4, 5, 6, 7, 0],<br/>\n",
    " [0, 7, 8, 9,10, 0],<br/>\n",
    " [0, 1, 3, 5, 7, 0],<br/>\n",
    " [0, 0, 0, 0, 0, 0]]\n",
    " \n",
    "再使用Filter對C做Convolution得到D為：\n",
    "\n",
    "[[1, 2, 3, 4],<br/>\n",
    " [4, 6, 8,10],<br/>\n",
    " [7,12,14,16],<br/>\n",
    " [1,10,13,16]]\n",
    " \n",
    "這個時候就是一個4x4的矩陣。\n",
    "\n",
    "Convolution的過程造成怎麼樣的效果呢？當Filter是一個鳥嘴的小圖，一旦遇到與鳥嘴相似的局部，此時加總的值會是一個大的值，如果是一個和鳥嘴無關的局部此時的值會是一個小的值，所以這個Filter具有將特定特徵篩選出來的能力，因此局部的特徵變得是有意義的，此時我的Model就具有局域性，而且藉由Filter的平移掃視，這個特徵就具有可平移的特性。\n",
    "\n",
    "Convolution Layer不同於Fully-connected Layer有兩點，第一，每個Pixels間有相對的距離關係，擁有上下左右的關係才有辦法構成一張圖，第二，除了有距離上的關係以外，它還能在有限範圍內抓出一種特徵模式，所以我們將可以使用影像的語言來做特徵轉換和抓取特徵。\n",
    "\n",
    "實際情況下，Filter上的Weights是會自行調整的，Model Fitting的時候，Model會根據數據自行訓練出Filter，也就是說機器可以自行學習出圖片的特徵。通常這樣的Filters會有好幾個，讓機器可以有更多維度可以學習。\n",
    "\n",
    "接下來來看Pooling Layer如何讓Model擁有檢視縮放的特性？\n",
    "\n",
    "先來看在影像上如何做到放大縮小，以Pixels的觀點來看，最簡單的放大方法是，在每個既有的Pixels附近增加一些與它們相似的新Pixel，這樣做就像是將原本的小圖直接拉成大圖，畫質雖然很差，不過這是最簡單的放大方法。那麼縮小就相反操作，把一群附近的Pixels濃縮成一個Pixel當作代表，就可以達到縮小圖片的效果。\n",
    "\n",
    "所以回到Pooling Layer的討論，Pooling做的事情就是在縮小圖片，例如我使用2x2來做Pooling，它會在原圖上以2x2來掃描，所以會有四個元素被檢視，我將會從這四個值當中產生一個值，如果是Max Pooling就是從四個中選最大的那個，如果是Average Pooling則是平均四個值得到平均值，通常如果是2x2的Pooling我們會以每2格一跳的方式掃視，如果是3x3則會以每3格一跳，以此類推。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convolution Layer\n",
    "\n",
    "來看一下Tensorflow如何實作Convolution Layer。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of conv:\n",
      "(1, 4, 4, 1)\n",
      "Conv:\n",
      "[[[[ 14.]\n",
      "   [  2.]\n",
      "   [  0.]\n",
      "   [  3.]]\n",
      "\n",
      "  [[  3.]\n",
      "   [  0.]\n",
      "   [  2.]\n",
      "   [ 14.]]\n",
      "\n",
      "  [[  3.]\n",
      "   [  0.]\n",
      "   [  6.]\n",
      "   [  6.]]\n",
      "\n",
      "  [[  1.]\n",
      "   [  0.]\n",
      "   [  2.]\n",
      "   [  1.]]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    img =tf.constant([[[[1],[2],[0],[0],[0]],\n",
    "                       [[3],[0],[0],[1],[2]],\n",
    "                       [[0],[0],[0],[3],[0]],\n",
    "                       [[1],[0],[0],[1],[0]],\n",
    "                       [[0],[0],[0],[0],[0]]]],tf.float32)\n",
    "    # shape of img: [batch, in_height, in_width, in_channels]\n",
    "    \n",
    "    filter_ = tf.constant([[[[1]],[[2]]],\n",
    "                           [[[3]],[[0]]]],tf.float32)\n",
    "    # shape of filter: [filter_height, filter_width, in_channels, out_channels]\n",
    "    \n",
    "    conv_strides = (1,1)\n",
    "    padding_method = 'VALID'\n",
    "    \n",
    "    conv = tf.nn.conv2d(img, filter_, \n",
    "                        strides=[1,conv_strides[0],conv_strides[1],1], \n",
    "                        padding=padding_method)\n",
    "    print(\"Shape of conv:\")\n",
    "    print(conv.eval().shape)\n",
    "    print(\"Conv:\")\n",
    "    print(conv.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先一開始是圖片`img`的部分，Rank為4，每個維度分別為`[batch, in_height, in_width, in_channels]`，in_channels的部分一般是RGB，這邊我採用和MNIST相同的灰階表示，所以in_channels只有1個維度。\n",
    "\n",
    "`filter_`的部分Rank為4，每個維度分別為`[filter_height, filter_width, in_channels, out_channels]`，當如果我想要使用多個filters的時候，我的out_channels就不只1而已，如果有RGB的話，in_channels則會是3。\n",
    "\n",
    "接下來來看一下`tf.nn.conv2d`裡頭的參數`strides`，這可能會讓人感到困惑，它的設定值是`[1,conv_strides[0],conv_strides[1],1]`，我特別把第二、三項額外用`conv_strides`來表示，因為這兩個值才是真正代表在圖片上平移每步的距離，那第一項和最後一項的1代表什麼意義呢？是這樣的，Tensorflow是站在維度的角度看平移這件事情，這四個維度分別表示`[batch, in_height, in_width, in_channels]`的移動量，所以一般情況下只有`in_height`和`in_width`需要指定平移的距離。\n",
    "\n",
    "最後一個參數就是`padding`，有兩種可以選擇，分別為`VALID`和`SAME`，`VALID`指的就是沒有額外鋪上0的邊界的情形，`SAME`則是額外鋪上0的邊界，並且使得輸出的維度和輸入一樣。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling Layer\n",
    "\n",
    "接下來來看Tensorflow如何實作Pooling Layer。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of pooling:\n",
      "(1, 2, 2, 1)\n",
      "Pooling:\n",
      "[[[[ 3.]\n",
      "   [ 1.]]\n",
      "\n",
      "  [[ 1.]\n",
      "   [ 3.]]]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    img =tf.constant([[[[1],[2],[0],[0]],\n",
    "                       [[3],[0],[0],[1]],\n",
    "                       [[0],[0],[0],[3]],\n",
    "                       [[1],[0],[0],[1]]]],tf.float32)\n",
    "    # shape of img: [batch, in_height, in_width, in_channels]\n",
    "    \n",
    "    pooling = tf.nn.max_pool(img,\n",
    "                    ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "    print(\"Shape of pooling:\")\n",
    "    print(pooling.eval().shape)\n",
    "    print(\"Pooling:\")\n",
    "    print(pooling.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.nn.max_pool`的參數中`ksize`代表kernel size，也就是要Pooling的大小，一樣依照Input layer的Rank去配置，還有`strides`決定平移的方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最簡單的CNN架構：LeNet5\n",
    "\n",
    "![LeNet5](https://raw.githubusercontent.com/GitYCC/Tensorflow_Tutorial/master/img/TensorflowTutorial.006.jpeg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNLogisticClassification(object):\n",
    "    def __init__(self,shape_picture,n_labels,\n",
    "                 learning_rate=0.5,dropout_ratio=0.5,alpha=0.0):\n",
    "        self.shape_picture = shape_picture\n",
    "        self.n_labels = n_labels\n",
    "        \n",
    "        self.weights = None\n",
    "        self.biases = None\n",
    "        \n",
    "        self.graph = tf.Graph() # initialize new grap\n",
    "        self.build(learning_rate,dropout_ratio,alpha) # building graph\n",
    "        self.sess = tf.Session(graph=self.graph) # create session by the graph \n",
    "        \n",
    "    def build(self,learning_rate,dropout_ratio,alpha):\n",
    "        with self.graph.as_default():\n",
    "            ### Input\n",
    "            self.train_pictures = tf.placeholder(tf.float32, \n",
    "                                                 shape=[None]+self.shape_picture)\n",
    "            self.train_labels   = tf.placeholder(tf.int32, \n",
    "                                                 shape=(None,self.n_labels))\n",
    "\n",
    "            ### Optimalization\n",
    "            # build neurel network structure and get their predictions and loss\n",
    "            self.y_,self.original_loss = self.structure(pictures=self.train_pictures,\n",
    "                                                        labels=self.train_labels,\n",
    "                                                        dropout_ratio=dropout_ratio,\n",
    "                                                        train=True, )\n",
    "            # regularization loss\n",
    "            self.regularization = tf.reduce_mean(\n",
    "                                   [tf.nn.l2_loss(w)/tf.size(w,out_type=tf.float32)\n",
    "                                        for w in self.weights.values()])\n",
    "            # total loss\n",
    "            self.loss = self.original_loss + alpha * self.regularization\n",
    "            \n",
    "            # define training operation\n",
    "            optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "            self.train_op = optimizer.minimize(self.loss)\n",
    "            \n",
    "            ### Prediction\n",
    "            self.new_pictures = tf.placeholder(tf.float32, \n",
    "                                               shape=[None]+self.shape_picture)\n",
    "            self.new_labels   = tf.placeholder(tf.int32, \n",
    "                                               shape=(None,self.n_labels))\n",
    "            self.new_y_,self.new_loss = self.structure(pictures=self.new_pictures,\n",
    "                                                       labels=self.new_labels,)\n",
    "            \n",
    "            ### Initialization\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "    \n",
    "    def structure(self,pictures,labels,dropout_ratio=None,train=False):\n",
    "        \n",
    "        ### Variable\n",
    "        ## LeNet5 Architecture(http://yann.lecun.com/exdb/lenet/) \n",
    "        # input:(batch,28,28,1) => conv1[5x5,6] => (batch,24,24,6)\n",
    "        # pool2 => (batch,12,12,6) => conv2[5x5,16] => (batch,8,8,16)\n",
    "        # pool4 => fatten5 => (batch,4x4x16) => fc6 => (batch,84)\n",
    "        # (batch,84) => fc7 => (batch,10) => softmax\n",
    "        \n",
    "        if (not self.weights) and (not self.biases):\n",
    "            self.weights = {\n",
    "                'conv1': tf.Variable(tf.truncated_normal(shape=(5,5,1,6),\n",
    "                                                         stddev=0.1)), \n",
    "                'conv3': tf.Variable(tf.truncated_normal(shape=(5,5,6,16),\n",
    "                                                         stddev=0.1)),\n",
    "                'fc6':   tf.Variable(tf.truncated_normal(shape=(4*4*16,84),\n",
    "                                                         stddev=0.1)),\n",
    "                'fc7':   tf.Variable(tf.truncated_normal(shape=(84,self.n_labels),\n",
    "                                                         stddev=0.1)),    \n",
    "            }\n",
    "            self.biases  = {\n",
    "                'conv1': tf.Variable(tf.zeros( shape=(6) )),\n",
    "                'conv3': tf.Variable(tf.zeros( shape=(16) )),\n",
    "                'fc6':   tf.Variable(tf.zeros( shape=(84) )),\n",
    "                'fc7':   tf.Variable(tf.zeros( shape=(self.n_labels) )),\n",
    "            } \n",
    "        \n",
    "        ### Structure\n",
    "        conv1 = self.getConv2DLayer(pictures,\n",
    "                                    self.weights['conv1'],self.biases['conv1'],\n",
    "                                    activation=tf.nn.relu)\n",
    "        pool2 = tf.nn.max_pool(conv1,\n",
    "                               ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "        conv3 = self.getConv2DLayer(pool2,\n",
    "                                    self.weights['conv3'],self.biases['conv3'],\n",
    "                                    activation=tf.nn.relu)\n",
    "        pool4 = tf.nn.max_pool(conv3,\n",
    "                               ksize=[1,2,2,1],strides=[1,2,2,1],padding='VALID')\n",
    "        fatten5 = self.getFlattenLayer(pool4)\n",
    "        \n",
    "        if train: fatten5 = tf.nn.dropout(fatten5,keep_prob=1-dropout_ratio[0])\n",
    "        \n",
    "        fc6 = self.getDenseLayer(fatten5,\n",
    "                                 self.weights['fc6'],self.biases['fc6'],\n",
    "                                 activation=tf.nn.relu)\n",
    "        \n",
    "        if train: fc6 = tf.nn.dropout(fc6,keep_prob=1-dropout_ratio[1])\n",
    "            \n",
    "        logits = self.getDenseLayer(fc6,self.weights['fc7'],self.biases['fc7'])\n",
    "        \n",
    "        y_ = tf.nn.softmax(logits)\n",
    "        loss = tf.reduce_mean(\n",
    "                 tf.nn.softmax_cross_entropy_with_logits(labels=labels,\n",
    "                                                         logits=logits))\n",
    "\n",
    "        return (y_,loss)\n",
    "    \n",
    "    def getDenseLayer(self,input_layer,weight,bias,activation=None):\n",
    "        x = tf.add(tf.matmul(input_layer,weight),bias)\n",
    "        if activation:\n",
    "            x = activation(x)\n",
    "        return x\n",
    "    \n",
    "    def getConv2DLayer(self,input_layer,\n",
    "                       weight,bias,\n",
    "                       strides=(1,1),padding='VALID',activation=None):\n",
    "        x = tf.add(\n",
    "              tf.nn.conv2d(input_layer,\n",
    "                           weight,\n",
    "                           [1,strides[0],strides[1],1],\n",
    "                           padding=padding),bias)\n",
    "        if activation:\n",
    "            x = activation(x)\n",
    "        return x\n",
    "\n",
    "    def getFlattenLayer(self,input_layer):\n",
    "        shape = input_layer.get_shape().as_list()\n",
    "        n = 1\n",
    "        for s in shape[1:]:\n",
    "            n *= s\n",
    "        x = tf.reshape(input_layer,[-1,n])\n",
    "        return x\n",
    "    \n",
    "    def fit(self,X,y,epochs=10,\n",
    "            validation_data=None,test_data=None,batch_size=None):\n",
    "        X = self._check_array(X)\n",
    "        y = self._check_array(y)\n",
    "        \n",
    "        N = X.shape[0]\n",
    "        random.seed(9000)\n",
    "        if not batch_size: batch_size=N\n",
    "        \n",
    "        self.sess.run(self.init_op)\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch %2d/%2d: \"%(epoch+1,epochs))\n",
    "            \n",
    "            # mini-batch gradient descent\n",
    "            index = [i for i in range(N)]\n",
    "            random.shuffle(index)\n",
    "            while len(index)>0:\n",
    "                index_size = len(index)\n",
    "                batch_index=[index.pop() for _ in range(min(batch_size,index_size))]    \n",
    "            \n",
    "                feed_dict = {\n",
    "                    self.train_pictures: X[batch_index,:], \n",
    "                    self.train_labels: y[batch_index], \n",
    "                }\n",
    "                _, loss = self.sess.run([self.train_op, self.loss],\n",
    "                                        feed_dict=feed_dict)\n",
    "                \n",
    "                print(\"[%d/%d] loss = %.4f     \"%(N-len(index),N,loss),end='\\r')\n",
    "\n",
    "            \n",
    "            # evaluate at the end of this epoch\n",
    "            y_ = self.predict(X)\n",
    "            train_loss = self.evaluate(X,y)\n",
    "            train_acc = self.accuracy(y_,y)\n",
    "            msg = \"[%d/%d] loss = %8.4f, acc = %3.2f%%\"%(N,N,train_loss,train_acc*100)\n",
    "            \n",
    "            if validation_data:\n",
    "                val_loss = self.evaluate(validation_data[0],validation_data[1])\n",
    "                val_acc = self.accuracy(self.predict(validation_data[0]),validation_data[1])\n",
    "                msg+=\", val_loss = %8.4f, val_acc = %3.2f%%\"%( val_loss, val_acc*100 )\n",
    "            \n",
    "            print(msg)\n",
    "            \n",
    "            \n",
    "        if test_data:\n",
    "            test_acc = self.accuracy(self.predict(test_data[0]),test_data[1])\n",
    "            print(\"test_acc = %3.2f%%\" % (test_acc*100))\n",
    "            \n",
    "    def accuracy(self, predictions, labels):\n",
    "        return (np.sum(np.argmax(predictions,1)==np.argmax(labels,1))/predictions.shape[0])\n",
    "    \n",
    "    def predict(self,X):\n",
    "        X = self._check_array(X)\n",
    "        return self.sess.run(self.new_y_, feed_dict={self.new_pictures: X})\n",
    "    \n",
    "    def evaluate(self,X,y):\n",
    "        X = self._check_array(X)\n",
    "        y = self._check_array(y)\n",
    "        return self.sess.run(self.new_loss, feed_dict={self.new_pictures: X, \n",
    "                                                       self.new_labels: y})\n",
    "    \n",
    "    def _check_array(self,ndarray):\n",
    "        ndarray = np.array(ndarray)\n",
    "        if len(ndarray.shape)==1: \n",
    "            ndarray=np.reshape(ndarray,(1,ndarray.shape[0]))\n",
    "        return ndarray\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "train_data = mnist.train\n",
    "valid_data = mnist.validation\n",
    "test_data = mnist.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/10: \n",
      "[55000/55000] loss =   0.1055, acc = 96.74%, val_loss =   0.1032, val_acc = 96.88%\n",
      "Epoch  2/10: \n",
      "[55000/55000] loss =   0.0776, acc = 97.61%, val_loss =   0.0820, val_acc = 97.64%\n",
      "Epoch  3/10: \n",
      "[55000/55000] loss =   0.0643, acc = 98.01%, val_loss =   0.0668, val_acc = 98.00%\n",
      "Epoch  4/10: \n",
      "[55000/55000] loss =   0.0487, acc = 98.51%, val_loss =   0.0560, val_acc = 98.26%\n",
      "Epoch  5/10: \n",
      "[55000/55000] loss =   0.0517, acc = 98.39%, val_loss =   0.0615, val_acc = 98.20%\n",
      "Epoch  6/10: \n",
      "[55000/55000] loss =   0.0407, acc = 98.75%, val_loss =   0.0501, val_acc = 98.48%\n",
      "Epoch  7/10: \n",
      "[55000/55000] loss =   0.0373, acc = 98.86%, val_loss =   0.0481, val_acc = 98.54%\n",
      "Epoch  8/10: \n",
      "[55000/55000] loss =   0.0370, acc = 98.83%, val_loss =   0.0499, val_acc = 98.60%\n",
      "Epoch  9/10: \n",
      "[55000/55000] loss =   0.0334, acc = 98.96%, val_loss =   0.0460, val_acc = 98.60%\n",
      "Epoch 10/10: \n",
      "[55000/55000] loss =   0.0319, acc = 98.97%, val_loss =   0.0413, val_acc = 98.64%\n",
      "test_acc = 98.79%\n"
     ]
    }
   ],
   "source": [
    "model = CNNLogisticClassification(   shape_picture=[28,28,1],\n",
    "                                     n_labels=10,\n",
    "                                     learning_rate=0.06,\n",
    "                                     dropout_ratio=[0.2,0.6],\n",
    "                                     alpha=0.1,\n",
    "                                 )\n",
    "\n",
    "train_img = np.reshape(train_data.images,[-1,28,28,1])\n",
    "valid_img = np.reshape(valid_data.images,[-1,28,28,1])\n",
    "test_img  = np.reshape(test_data.images,[-1,28,28,1])\n",
    "\n",
    "model.fit(X=train_img,\n",
    "          y=train_data.labels,\n",
    "          epochs=10,\n",
    "          validation_data=(valid_img,valid_data.labels),\n",
    "          test_data=(test_img,test_data.labels),\n",
    "          batch_size = 32,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
