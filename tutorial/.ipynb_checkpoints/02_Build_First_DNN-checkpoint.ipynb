{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "# Config the matplotlib backend as plotting inline in IPython\n",
    "%matplotlib inline\n",
    "\n",
    "def summary(ndarr):\n",
    "    print(ndarr)\n",
    "    print(\"* shape: {}\".format(ndarr.shape))\n",
    "    print(\"* min: {}\".format(np.min(ndarr)))\n",
    "    print(\"* max: {}\".format(np.max(ndarr)))\n",
    "    print(\"* avg: {}\".format(np.mean(ndarr)))\n",
    "    print(\"* std: {}\".format(np.std(ndarr)))\n",
    "    print(\"* unique: {}\".format(np.unique(ndarr)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "\n",
    "train_data = mnist.train\n",
    "valid_data = mnist.validation\n",
    "test_data = mnist.test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DNNLogisticClassification(object):\n",
    "    def __init__(self,n_features,n_labels,learning_rate=0.5,n_hidden=1000,dropout_ratio=0.5,alpha=0.0):\n",
    "        self.n_features = n_features\n",
    "        self.n_labels = n_labels\n",
    "        self.graph = tf.Graph()\n",
    "        self.build(learning_rate,n_hidden,dropout_ratio,alpha)\n",
    "        self.sess = tf.Session(graph=self.graph)\n",
    "        \n",
    "    def build(self,learning_rate,n_hidden,dropout_ratio,alpha):\n",
    "        with self.graph.as_default():\n",
    "            # Input\n",
    "            self.features = tf.placeholder(tf.float32, shape=(None,self.n_features))\n",
    "            self.labels   = tf.placeholder(tf.int32  , shape=(None,self.n_labels))\n",
    "            \n",
    "            # Computation\n",
    "            self.W1, self.b1, self.s1 = self.getDenseLayer(self.features,n_hidden)\n",
    "            self.drop_s1 = tf.nn.dropout(self.s1, keep_prob=(1-dropout_ratio))\n",
    "            self.x2 = tf.nn.relu(self.drop_s1)\n",
    "            self.W2, self.b2, self.s2 = self.getDenseLayer(self.x2,self.n_labels)\n",
    "    \n",
    "            self.y = tf.nn.softmax(self.s2)\n",
    "            \n",
    "            # Optimalization\n",
    "            self.original_loss = tf.reduce_mean(\n",
    "                            tf.nn.softmax_cross_entropy_with_logits(labels=self.labels, logits=self.s2))\n",
    "            self.regularization = tf.nn.l2_loss(self.W1) + tf.nn.l2_loss(self.W2)\n",
    "            self.loss = self.original_loss + alpha * self.regularization\n",
    "            \n",
    "            self.train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(self.loss)\n",
    "            \n",
    "            # Initialization\n",
    "            self.init_op = tf.global_variables_initializer()\n",
    "            \n",
    "    def getDenseLayer(self,input_layer,n_output):\n",
    "        with self.graph.as_default():\n",
    "            n_input = int(input_layer.shape[1])\n",
    "            W = tf.Variable(\n",
    "                    tf.truncated_normal( shape=(n_input,n_output) ))\n",
    "            b = tf.Variable(tf.zeros( shape=(n_output) ))\n",
    "            s = tf.matmul(input_layer,W)+b\n",
    "        return (W,b,s)\n",
    "    \n",
    "    def fit(self,X,y,epochs=10,validation_data=None,test_data=None,batch_size=None):\n",
    "        N = X.shape[0]\n",
    "        random.seed(9000)\n",
    "        if not batch_size: batch_size=N\n",
    "        \n",
    "        self.sess.run(self.init_op)\n",
    "        for epoch in range(epochs):\n",
    "            print(\"Epoch %2d/%2d: \"%(epoch+1,epochs))\n",
    "            index = random.shuffle([i for i in range(N)])\n",
    "\n",
    "            k = 0\n",
    "            while k < N:\n",
    "                batch_index = [i for i in range(k,min(k+batch_size,N))]    \n",
    "            \n",
    "                feed_dict = {self.features: X[batch_index,:], self.labels: y[batch_index]}\n",
    "                _, loss, predictions = self.sess.run([self.train_op, self.loss, self.y], feed_dict=feed_dict)\n",
    "                \n",
    "                print(\"[%d/%d] loss = %9.4f                      \" % ( k, N, loss ), end='\\r')\n",
    "                \n",
    "                k += batch_size\n",
    "            \n",
    "            msg_valid = \"\"\n",
    "            if validation_data:\n",
    "                val_loss = self.evaluate(validation_data[0],validation_data[1])\n",
    "                val_acc = self.accuracy(self.predict(validation_data[0]),validation_data[1])\n",
    "                msg_valid = \", val_loss = %9.4f, val_acc = %3.2f%%\" % ( val_loss,val_acc*100 )\n",
    "            \n",
    "            train_loss = self.evaluate(X,y)\n",
    "            train_acc = self.accuracy(self.predict(X),y)\n",
    "            print(\"[%d/%d] loss = %9.4f, acc = %3.2f%% %s\" % ( N, N, train_loss, train_acc*100, msg_valid ))\n",
    "            \n",
    "            \n",
    "        if test_data:\n",
    "            test_acc = self.accuracy(self.predict(test_data[0]),test_data[1])\n",
    "            print(\"test_acc = %3.2f%%\" % (test_acc*100))\n",
    "            \n",
    "    def accuracy(self, predictions, labels):\n",
    "        return (np.sum(np.argmax(predictions, 1) == np.argmax(labels, 1))/predictions.shape[0])\n",
    "    \n",
    "    def predict(self,X):\n",
    "        return self.sess.run(self.y, feed_dict={self.features: X})\n",
    "    \n",
    "    def evaluate(self,X,y):\n",
    "        return self.sess.run(self.loss, feed_dict={self.features: X, self.labels: y})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch  1/ 5: \n",
      "[55000/55000] loss =  201.0457, acc = 85.26% , val_loss =  201.1630, val_acc = 85.98%\n",
      "Epoch  2/ 5: \n",
      "[55000/55000] loss =  130.4622, acc = 88.39% , val_loss =  130.5526, val_acc = 88.16%\n",
      "Epoch  3/ 5: \n",
      "[55000/55000] loss =   84.7895, acc = 91.08% , val_loss =   84.8732, val_acc = 90.08%\n",
      "Epoch  4/ 5: \n",
      "[55000/55000] loss =   55.1698, acc = 93.08% , val_loss =   55.2244, val_acc = 92.46%\n",
      "Epoch  5/ 5: \n",
      "[55000/55000] loss =   35.9403, acc = 93.73% , val_loss =   35.9862, val_acc = 92.70%\n",
      "test_acc = 92.89%\n"
     ]
    }
   ],
   "source": [
    "model = DNNLogisticClassification(   n_features=28*28,\n",
    "                                     n_labels=10,\n",
    "                                     learning_rate= 0.5,\n",
    "                                     n_hidden=1000,\n",
    "                                     alpha=0.001,\n",
    "                                 )\n",
    "model.fit(X=train_data.images,\n",
    "          y=train_data.labels,\n",
    "          epochs=5,\n",
    "          validation_data=(valid_data.images,valid_data.labels),\n",
    "          test_data=(test_data.images,test_data.labels),\n",
    "          batch_size = 128,\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
